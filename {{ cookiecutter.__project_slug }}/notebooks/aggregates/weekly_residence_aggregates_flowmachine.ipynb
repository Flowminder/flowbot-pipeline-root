{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8b66f2-bd57-4029-bb52-149e547cc3af",
   "metadata": {},
   "source": [
    "James Harrison, 2023-06-02\n",
    "\n",
    "This is a modified version of 'run_weekly_aggregates.ipynb' which runs the aggregates using flowmachine directly, so that aggregates can optionally be unredacted.\n",
    "\n",
    "This notebook is used to produce the following aggregates:\n",
    "- Resident counts per 7-day rolling window\n",
    "- Home relocations between consecutive 7-day rolling windows (i.e. offset by 1 day, unless some 7-day windows are skipped due to missing data)\n",
    "- Home relocations between disjoint 7-day rolling windows (i.e. offset by 7 days)\n",
    "\n",
    "for each day in the specified date range (by default, the most recently-ended full calendar month before today).\n",
    "\n",
    "These aggregates are intended to be produced on an ongoing basis in preparation for crisis response work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1b1fc-c512-4cda-8fe6-8122b289aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import datetime\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import flowmachine as fm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from apply_subscriber_set import ApplySubscriberSet\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from flowclient.aggregates import (\n",
    "    flows_spec,\n",
    "    inflows_spec,\n",
    "    outflows_spec,\n",
    "    spatial_aggregate_spec,\n",
    ")\n",
    "from flowmachine.core.union import Union\n",
    "from flowmachine.features.subscriber.per_subscriber_aggregate import (\n",
    "    PerSubscriberAggregate,\n",
    ")\n",
    "from flowmachine.features.utilities.unique_values_from_queries import (\n",
    "    UniqueValuesFromQueries,\n",
    ")\n",
    "from total_locatable_periods import TotalLocatablePeriods\n",
    "from utils import (\n",
    "    _write_query_result,\n",
    "    daily_home_location_specs,\n",
    "    find_dates_to_exclude,\n",
    "    get_date_in_month,\n",
    "    rolling_window_over_date_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14443a00-5399-495a-94e5-c2942b10c93c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c5db11-1689-4cb2-b0ff-21dd8337238e",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc4a7b-58aa-4aeb-9a65-9e86278e5017",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_now = datetime.datetime.now()\n",
    "datetime_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d95bb8-dea3-44ba-b5b6-cb42eb18ea98",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "author = \"James Harrison <james.harrison@flowminder.org>\"\n",
    "\n",
    "start_date = get_date_in_month(\n",
    "    datetime_now, day_of_month=1, month_offset=-1\n",
    ")  # Start date of the data interval (inclusive)\n",
    "logical_date = datetime_now\n",
    "window_length = (\n",
    "    7  # Length in days of the rolling window used to compute average call days\n",
    ")\n",
    "min_call_days = (\n",
    "    2  # Minimal number of average days in a window a subscriber was sighted on\n",
    ")\n",
    "latest_truncation_threshold = (\n",
    "    \"18:00:00\"  # Threshold for excluding temporally-truncated data\n",
    ")\n",
    "\n",
    "aggregation_unit = \"lon-lat\"  # Spatial aggregation unit\n",
    "mapping_table = \"geography.cell_to_admin_via_clusters_1km_20221025\"\n",
    "geom_table = \"geography.clusters_1km_20221025\"\n",
    "geom_table_join_column = \"cluster_id\"\n",
    "event_types = [\"calls\"]  # Event types to use\n",
    "\n",
    "flowmachine_log_level = \"info\"  # Flowmachine log level\n",
    "shared_data_dir = \"./\"  # Writable output directory\n",
    "outputs_subdir = \"aggregates/crisis_response\"  # Subdirectory of shared data dir to which results of aggregate queries will be written\n",
    "output_format = \"csv\"  # 'csv' or 'netcdf'\n",
    "overwrite = False  # Set True to overwrite previously-saved aggregates for this month (with overwrite=False, conflicting aggregate files will be renamed)\n",
    "calculate_relocations = True  # Set False to skip running the home relocations aggregate\n",
    "require_latest_data = True  # If True, computation will not proceed if the last required day of data is later than the most recent available date\n",
    "include_subsetted = True  # Set False to skip calculating aggregates using an \"active subset\" of subscribers\n",
    "redact = False  # Set True to redact small counts from the aggregate outputs (as would be the case for results retrieved through the API)\n",
    "aggregates_to_run = None  # Optionally specify a subset of aggregate kinds to run (ideally we wouldn't have this option and calculate_relocations as separate parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161bbd27-f2cc-494a-b2be-e18f1200d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start/end date parameters may be strings, so convert to datetime.date\n",
    "start_date = pd.Timestamp(start_date).date()\n",
    "logical_date = pd.Timestamp(logical_date).date()\n",
    "end_date = logical_date + relativedelta(days=1)\n",
    "\n",
    "(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d70e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct outputs path (we don't actually create the dir until we're ready to start writing outputs later)\n",
    "outputs_path = (\n",
    "    Path(shared_data_dir)\n",
    "    / outputs_subdir\n",
    "    / f\"weekly_aggregates_{aggregation_unit}_{logical_date:%Y-%m-%d}\"\n",
    ")\n",
    "\n",
    "outputs_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018b3f3-4fa6-4b4f-8500-8810980a03bc",
   "metadata": {},
   "source": [
    "## Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6ccd2-40c9-432a-b795-70b6f3f48072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even if we're not using a subscriber subset, flowmachine connection is required to get the earliest/latest event time per day\n",
    "fm.connect(\n",
    "    flowdb_connection_pool_overflow=20,\n",
    "    flowdb_connection_pool_size=5,\n",
    "    log_level=flowmachine_log_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18315e-f6e2-4a46-b161-cc69f83d6bce",
   "metadata": {},
   "source": [
    "## Check dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4bc884-bb8c-467f-b399-e80498eb4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_to_skip = find_dates_to_exclude(\n",
    "    flowdb_connection=fm.core.context.get_db(),\n",
    "    # Kludge fix - I think something else is looking relative to the start of the month and isn't getting checks for missing dates here. -John\n",
    "    start_date=start_date - relativedelta(days=window_length + 30),\n",
    "    end_date=end_date,\n",
    "    event_types=event_types,\n",
    "    latest_truncation_threshold=latest_truncation_threshold,\n",
    "    fail_on_missing_latest=require_latest_data,\n",
    ")\n",
    "dates_to_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a403ae8-cbab-4194-bf2f-1426c8d7a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rolling windows\n",
    "rolling_windows = rolling_window_over_date_range(\n",
    "    start_date=start_date - relativedelta(days=window_length),\n",
    "    end_date=end_date,\n",
    "    window_length=window_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b3461d-8ce4-4bcd-82c5-9393d42466f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for empty windows\n",
    "empty_windows = sorted(\n",
    "    [\n",
    "        d\n",
    "        for d in rolling_windows\n",
    "        if not set(\n",
    "            str(d.date())\n",
    "            for d in pd.date_range(\n",
    "                rolling_windows[d][0], rolling_windows[d][1], inclusive=\"left\"\n",
    "            )\n",
    "        ).difference(dates_to_skip)\n",
    "    ]\n",
    ")\n",
    "\n",
    "if empty_windows:\n",
    "    warnings.warn(\n",
    "        f\"Windows for dates {empty_windows} have no data. Aggregates will not be produced for these dates.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6bb495-c07b-4f08-8928-a4ae1faaf43b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Subscriber subset\n",
    "\n",
    "Subscriber subsets have to be defined and run using flowmachine directly, and then the query IDs can be used to subset FlowAPI queries.\n",
    "\n",
    "Subscriber subset is the set of subscribers who are active on `min_call_days` days in every non-empty `window_length`-day rolling window on average (median) over the specified date range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f467158-2b3d-4052-911b-c4889f01e02d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define subscriber subset queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49fe56d-2b76-44cb-8aa3-4c4ee6638d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_subsetted:\n",
    "    tables = [f\"events.{event_type}\" for event_type in event_types]\n",
    "    # Convert FlowAPI aggregation unit parameters to a flowmachine spatial unit\n",
    "    if \"admin\" in aggregation_unit:\n",
    "        spatial_unit = fm.core.spatial_unit.make_spatial_unit(\n",
    "            spatial_unit_type=\"admin\",\n",
    "            level=int(aggregation_unit[-1]),\n",
    "            mapping_table=mapping_table,\n",
    "            geom_table=geom_table,\n",
    "            geom_table_join_on=geom_table_join_column,\n",
    "        )\n",
    "    else:\n",
    "        spatial_unit = fm.core.spatial_unit.make_spatial_unit(\n",
    "            spatial_unit_type=aggregation_unit,\n",
    "            mapping_table=mapping_table,\n",
    "            geom_table=geom_table,\n",
    "            geom_table_join_on=geom_table_join_column,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a21bb0f-af75-4eeb-b329-5ba7d511c0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subset of subscribers with median call days per non-empty window >= `min_call_days`\n",
    "\n",
    "if include_subsetted:\n",
    "    # Count call days per subscriber per window over the month\n",
    "    # (excluding the first window_length windows because these belong to the previous month)\n",
    "    active_periods_queries = []\n",
    "    for window in sorted(\n",
    "        d\n",
    "        for d in rolling_windows.keys()\n",
    "        if datetime.date.fromisoformat(d) >= start_date\n",
    "    ):\n",
    "        try:\n",
    "            active_periods_queries.append(\n",
    "                TotalLocatablePeriods(\n",
    "                    start=rolling_windows[window][0],\n",
    "                    total_periods=window_length,\n",
    "                    period_length=1,\n",
    "                    period_unit=\"days\",\n",
    "                    spatial_unit=spatial_unit,\n",
    "                    table=tables,\n",
    "                    periods_to_exclude=dates_to_skip,\n",
    "                )\n",
    "            )\n",
    "        except ValueError:\n",
    "            # If all dates in this window are excluded, skip it\n",
    "            pass\n",
    "\n",
    "    # Need to fill counts with 0 for windows where a subscriber was inactive,\n",
    "    # so that the median can be calculated correctly. For this we need the set of\n",
    "    # all subscribers active in any of the windows.\n",
    "    all_active_subscribers_query = UniqueValuesFromQueries(\n",
    "        query_list=active_periods_queries,\n",
    "        column_names=\"subscriber\",\n",
    "    )\n",
    "    active_periods_for_all_subscribers_queries = []\n",
    "    for active_periods_query in active_periods_queries:\n",
    "        active_periods_for_all_subscribers_queries.append(\n",
    "            ApplySubscriberSet(\n",
    "                parent=active_periods_query,\n",
    "                subscriber_set=all_active_subscribers_query,\n",
    "                fill_values={\"value\": 0},\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Find subset of subscribers that were active at least min_call_days days per window (median)\n",
    "    subset_query = PerSubscriberAggregate(\n",
    "        subscriber_query=Union(*active_periods_for_all_subscribers_queries),\n",
    "        agg_column=\"value\",\n",
    "        agg_method=\"median\",\n",
    "    ).numeric_subset(high=np.inf, low=min_call_days, col=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b97fc0f-cb5a-4723-a76b-5d0763901c7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run subscriber subset query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf09877-5d96-47c3-95cc-386fb5f6bcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if include_subsetted:\n",
    "    subset_query.store(store_dependencies=True).result()\n",
    "    len(subset_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4f706-817a-4b06-aa45-2f19b6b8f030",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wrap in Table object so that flowmachine server can unpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb075eb5-ba01-4fc3-bba0-f4eb42adccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_subsetted:\n",
    "    subscriber_subset_table = subset_query.get_table()\n",
    "    subscriber_subset_query_id = subscriber_subset_table.query_id\n",
    "    subscriber_subset_query_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c8a8c-9d17-4e25-a1fe-56e42de0d8ad",
   "metadata": {},
   "source": [
    "Subset query id can now be passed on to API queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bafa820-0462-4e0c-ab76-a7807826d0ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FlowAPI side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a0317-ca5c-4c77-98c3-33342db440b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5d900-4f6b-444a-8c71-671dba16ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_specs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb658e89-7ecc-4b77-87c2-6a131d776a31",
   "metadata": {},
   "source": [
    "### Home location sub-queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f3d126-99fd-4129-8f0a-ce423da324dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_subsetted:\n",
    "    home_location_specs_subset = daily_home_location_specs(\n",
    "        rolling_windows=rolling_windows,\n",
    "        aggregation_unit=aggregation_unit,\n",
    "        mapping_table=mapping_table,\n",
    "        geom_table=geom_table,\n",
    "        geom_table_join_column=geom_table_join_column,\n",
    "        subscriber_subset=subscriber_subset_query_id,\n",
    "        event_types=event_types,\n",
    "        dates_to_exclude=dates_to_skip,\n",
    "    )\n",
    "    home_location_specs_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2349fb-02c8-451f-be14-2b906dfcce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_location_specs_nosubset = daily_home_location_specs(\n",
    "    rolling_windows=rolling_windows,\n",
    "    aggregation_unit=aggregation_unit,\n",
    "    mapping_table=mapping_table,\n",
    "    geom_table=geom_table,\n",
    "    geom_table_join_column=geom_table_join_column,\n",
    "    subscriber_subset=None,\n",
    "    event_types=event_types,\n",
    "    dates_to_exclude=dates_to_skip,\n",
    ")\n",
    "home_location_specs_nosubset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a5ac7-778b-4932-ac92-6158459720a3",
   "metadata": {},
   "source": [
    "### Resident counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f852c67-f082-4fe8-8112-56495392ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_subsetted:\n",
    "    for d in home_location_specs_subset:\n",
    "        # Don't produce resident counts for windows before start_date\n",
    "        if datetime.date.fromisoformat(d) >= start_date:\n",
    "            api_specs[f\"resident-counts_subset_{d}\"] = spatial_aggregate_spec(\n",
    "                locations=home_location_specs_subset[d],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80c804-04f6-4f52-8839-a72c84e78adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in home_location_specs_nosubset:\n",
    "    # Don't produce resident counts for windows before start_date\n",
    "    if datetime.date.fromisoformat(d) >= start_date:\n",
    "        api_specs[f\"resident-counts_nosubset_{d}\"] = spatial_aggregate_spec(\n",
    "            locations=home_location_specs_nosubset[d],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb53ef7-f017-4684-8823-52fe1803c6b4",
   "metadata": {},
   "source": [
    "### Home relocations matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c6042-c8e2-4bbc-bb41-9d8f42971b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_relocations:\n",
    "    non_empty_windows = sorted(home_location_specs_nosubset.keys())\n",
    "    for d_from, d_to in zip(non_empty_windows[:-1], non_empty_windows[1:]):\n",
    "        # Home relocations between consecutive windows (don't produce relocations for 'to' windows before start_date)\n",
    "        if datetime.date.fromisoformat(d_to) >= start_date:\n",
    "            if include_subsetted:\n",
    "                api_specs[\n",
    "                    f\"home-relocations_consecutive_subset_from{d_from}_to{d_to}\"\n",
    "                ] = flows_spec(\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to],\n",
    "                    join_type=\"full outer\",\n",
    "                )\n",
    "                api_specs[\n",
    "                    f\"home-relocations-in_consecutive_subset_from{d_from}_to{d_to}\"\n",
    "                ] = inflows_spec(\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to],\n",
    "                    join_type=\"inner\",\n",
    "                )\n",
    "                api_specs[\n",
    "                    f\"home-relocations-out_consecutive_subset_from{d_from}_to{d_to}\"\n",
    "                ] = outflows_spec(\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to],\n",
    "                    join_type=\"inner\",\n",
    "                )\n",
    "            api_specs[\n",
    "                f\"home-relocations_consecutive_nosubset_from{d_from}_to{d_to}\"\n",
    "            ] = flows_spec(\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to],\n",
    "                join_type=\"full outer\",\n",
    "            )\n",
    "            api_specs[\n",
    "                f\"home-relocations-in_consecutive_nosubset_from{d_from}_to{d_to}\"\n",
    "            ] = inflows_spec(\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to],\n",
    "                join_type=\"inner\",\n",
    "            )\n",
    "            api_specs[\n",
    "                f\"home-relocations-out_consecutive_nosubset_from{d_from}_to{d_to}\"\n",
    "            ] = outflows_spec(\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to],\n",
    "                join_type=\"inner\",\n",
    "            )\n",
    "        # Home relocations between disjoint windows\n",
    "        d_to_disjoint = str(\n",
    "            (pd.Timestamp(d_from) + pd.Timedelta(days=window_length)).date()\n",
    "        )\n",
    "        if d_to_disjoint in non_empty_windows:\n",
    "            if include_subsetted:\n",
    "                api_specs[\n",
    "                    f\"home-relocations_disjoint_subset_from{d_from}_to{d_to_disjoint}\"\n",
    "                ] = flows_spec(\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to_disjoint],\n",
    "                    join_type=\"full outer\",\n",
    "                )\n",
    "                api_specs[\n",
    "                    f\"home-relocations-in_disjoint_subset_from{d_from}_to{d_to_disjoint}\"\n",
    "                ] = inflows_spec(\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to_disjoint],\n",
    "                    join_type=\"inner\",\n",
    "                )\n",
    "                api_specs[\n",
    "                    f\"home-relocations-out_disjoint_subset_from{d_from}_to{d_to_disjoint}\"\n",
    "                ] = outflows_spec(\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to_disjoint],\n",
    "                    join_type=\"inner\",\n",
    "                )\n",
    "            api_specs[\n",
    "                f\"home-relocations_disjoint_nosubset_from{d_from}_to{d_to_disjoint}\"\n",
    "            ] = flows_spec(\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to_disjoint],\n",
    "                join_type=\"full outer\",\n",
    "            )\n",
    "            api_specs[\n",
    "                f\"home-relocations-in_disjoint_nosubset_from{d_from}_to{d_to_disjoint}\"\n",
    "            ] = inflows_spec(\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to_disjoint],\n",
    "                join_type=\"inner\",\n",
    "            )\n",
    "            api_specs[\n",
    "                f\"home-relocations-out_disjoint_nosubset_from{d_from}_to{d_to_disjoint}\"\n",
    "            ] = outflows_spec(\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to_disjoint],\n",
    "                join_type=\"inner\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0113fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88148602-ac8b-455e-a2f5-98fb2b3d5aaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41225694-dd2a-42a9-83ba-567c4dec3092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flowmachine.core.server.query_schemas import FlowmachineQuerySchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1bbe3-eb03-4028-b7d4-9e76fb939080",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_queries = {}\n",
    "for label, query_spec in api_specs.items():\n",
    "    print(label)\n",
    "    # TODO: would be better to skip creating the query specs altogether for non-required aggregates,\n",
    "    # but I want to add this functionality with minimal changes for now\n",
    "    if (aggregates_to_run is None) or any(\n",
    "        label.startswith(agg_name) for agg_name in aggregates_to_run\n",
    "    ):\n",
    "        fm_query_obj = FlowmachineQuerySchema().load(query_spec)._flowmachine_query_obj\n",
    "        if redact:\n",
    "            fm_queries[label] = (fm_query_obj, query_spec)\n",
    "        else:\n",
    "            unredacted_query_obj = fm_query_obj.redaction_target\n",
    "            fm_queries[label] = (unredacted_query_obj, query_spec)\n",
    "    else:\n",
    "        print(\"Skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14d12ab-0909-46d7-954d-7cd02631371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = [q[0].store(store_dependencies=True) for label, q in fm_queries.items()]\n",
    "concurrent.futures.wait(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3152ae",
   "metadata": {},
   "source": [
    "## Get results and write to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ead5f-5e18-4ad1-a3c6-029cda9eaa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b649e1d-13c8-42e5-926c-aacdf86a3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, (query, spec) in fm_queries.items():\n",
    "    print(label)\n",
    "    attrs = dict(\n",
    "        created_at=datetime.datetime.now().isoformat(),\n",
    "        flowmachine_version=fm.__version__,\n",
    "        parameters=json.dumps(spec),\n",
    "        author=author,\n",
    "        redacted=str(redact),\n",
    "        query_id=query.query_id,\n",
    "        excluded_dates=sorted(dates_to_skip),\n",
    "    )\n",
    "    if redact:\n",
    "        filepath = outputs_path / label\n",
    "    else:\n",
    "        filepath = outputs_path / f\"{label}_unredacted\"\n",
    "    _write_query_result(\n",
    "        query.get_dataframe(),\n",
    "        filepath,\n",
    "        file_format=output_format,\n",
    "        overwrite=overwrite,\n",
    "        attrs=attrs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc89c6a-8250-45da-aff5-644294a31d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
