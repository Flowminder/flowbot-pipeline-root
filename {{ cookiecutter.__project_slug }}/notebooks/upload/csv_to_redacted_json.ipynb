{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f99a8-d214-4f91-87eb-2411f4062e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import csv\n",
    "from pandas import DataFrame, read_csv\n",
    "from dataclasses import asdict\n",
    "from data_cleaning import (\n",
    "    csv_to_dataset,\n",
    "    RelocationsDataset,\n",
    "    ResidentsDataset,\n",
    "    MovementsDataset,\n",
    "    PresenceDataset,\n",
    "    validate_indicator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvalidIndicatorError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89752e-070f-4220-a991-08af7ce64300",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "shared_data_dir = Path(\n",
    "    \"../../tests/\"\n",
    ")  # The path to the shared_data_dir for this notebook (see FlowpyterOperator notes)\n",
    "dagrun_data_dir = Path(\"../../tests/\")\n",
    "static_dir = Path(\"../../tests/\")\n",
    "INDICATORS_FILES = {\n",
    "    \"sample_indicators/residents_indicators_2020-01_release.csv\": [\n",
    "        *ResidentsDataset(\"foobar\").indicators\n",
    "    ]\n",
    "}  # A dict of category_path:[indicators_to_upload]\n",
    "REDACTED_ADMIN_3_STATIC_PATH = \"redacted_sections.csv\"  # The path to the .csv containing a column 'pcod' of admin3 regions to redact\n",
    "CDR_POPULATION_FILE = \"cdr_pop_synth.csv\"\n",
    "JSON_OUTPUTS = \"outputs\"\n",
    "CONFIG_STATIC_PATH = \"config.json\"\n",
    "DATA_VERSION = \"JOHN_TEST_DATA\"\n",
    "IS_FIRST_MONTH = False  # Residents redaction rules are different for the first month\n",
    "ADMIN3_WITH_ACTIVITY_FILE = \"admin3s_with_cdr_activity.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1efa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary hack required until we update flowpyter-task to allow list params\n",
    "if isinstance(INDICATORS_FILES, str):\n",
    "    INDICATORS_FILES = json.loads(INDICATORS_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e23ad-f4e8-45fc-af43-da39bdbd234c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Postprocessing of parameters + af vars\n",
    "shared_data_dir = Path(shared_data_dir)\n",
    "dagrun_data_dir = Path(dagrun_data_dir)\n",
    "static_dir = Path(static_dir)\n",
    "INDICATORS = {shared_data_dir / path: inds for path, inds in INDICATORS_FILES.items()}\n",
    "JSON_FOLDER = dagrun_data_dir / JSON_OUTPUTS\n",
    "CDR_POPULATION_PATH = dagrun_data_dir / CDR_POPULATION_FILE\n",
    "CONFIG_PATH = static_dir / CONFIG_STATIC_PATH\n",
    "REDACTED_ADMIN_3_LIST = static_dir / REDACTED_ADMIN_3_STATIC_PATH\n",
    "ADMIN3_WITH_ACTIVITY_PATH = dagrun_data_dir / ADMIN3_WITH_ACTIVITY_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f955f2f-18d5-433d-8869-22b1f9a9ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redaction rules\n",
    "def get_redaction_list(redaction_list_path):\n",
    "    with open(redaction_list_path, \"r\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        return [row[\"pcod\"] for row in reader]\n",
    "\n",
    "\n",
    "def cdr_pop_redaction_residents(df: DataFrame) -> DataFrame:\n",
    "    cdr_pop = read_csv(CDR_POPULATION_PATH)\n",
    "    admin3s_above_threshold = cdr_pop.loc[cdr_pop[\"value\"] >= 200, \"pcod\"]\n",
    "    return df.loc[\n",
    "        df.index.get_level_values(\"spatial_unit\").isin(admin3s_above_threshold)\n",
    "    ]\n",
    "\n",
    "\n",
    "def cdr_pop_redaction_relocations(df: DataFrame) -> DataFrame:\n",
    "    cdr_pop = read_csv(CDR_POPULATION_PATH)\n",
    "    admin3s_above_threshold = cdr_pop.loc[cdr_pop[\"value\"] >= 200, \"pcod\"]\n",
    "    return df.loc[\n",
    "        df.index.get_level_values(\"origin\").isin(admin3s_above_threshold)\n",
    "        & df.index.get_level_values(\"destination\").isin(admin3s_above_threshold)\n",
    "    ]\n",
    "\n",
    "\n",
    "def cdr_activity_redaction_residents(df: DataFrame) -> DataFrame:\n",
    "    admin3s_with_cdr_activity = read_csv(ADMIN3_WITH_ACTIVITY_PATH)\n",
    "    return df.loc[\n",
    "        df.index.get_level_values(\"spatial_unit\").isin(\n",
    "            admin3s_with_cdr_activity[\"pcod\"]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "def admin_3_drop_residents(df: DataFrame) -> DataFrame:\n",
    "    return df.drop(get_redaction_list(REDACTED_ADMIN_3_LIST), level=1, errors=\"ignore\")\n",
    "\n",
    "\n",
    "def admin_3_drop_relocations(df: DataFrame) -> DataFrame:\n",
    "    df = df.drop(get_redaction_list(REDACTED_ADMIN_3_LIST), level=1, errors=\"ignore\")\n",
    "    return df.drop(get_redaction_list(REDACTED_ADMIN_3_LIST), level=2, errors=\"ignore\")\n",
    "\n",
    "\n",
    "def relocations_redaction(df: DataFrame) -> DataFrame:\n",
    "    indicies = df.loc[df[\"relocations\"] <= 15].index.values\n",
    "    return df.drop(indicies)\n",
    "\n",
    "\n",
    "def residents_redaction(df: DataFrame) -> DataFrame:\n",
    "    indicies = df.loc[df[\"residents\"] <= 15].index.values\n",
    "    return df.drop(indicies)\n",
    "\n",
    "\n",
    "def presence_redaction(df: DataFrame) -> DataFrame:\n",
    "    indicies = df.loc[df[\"presence\"] <= 15].index.values\n",
    "    return df.drop(indicies)\n",
    "\n",
    "\n",
    "def travellers_redaction(df: DataFrame) -> DataFrame:\n",
    "    indicies = df.loc[df[\"travellers\"] <= 15].index.values\n",
    "    return df.drop(indicies)\n",
    "\n",
    "\n",
    "def arrivals_departed_nan(df: DataFrame) -> DataFrame:\n",
    "    return df.dropna(subset=[\"arrived\", \"departed\"])\n",
    "\n",
    "\n",
    "def not_implemented_redaction(df):\n",
    "    raise NotImplementedError(\"Redactions not implemented for this dataset\")\n",
    "\n",
    "\n",
    "def round_residents(df) -> DataFrame:\n",
    "    col_dps = {\n",
    "        \"residents\": -2,\n",
    "        \"residents_perKm2\": -1,\n",
    "        \"arrived\": -1,\n",
    "        \"departed\": -1,\n",
    "        \"delta_arrived\": -1,\n",
    "        \"residents_diffwithref\": -1,\n",
    "        \"abnormality\": 3,\n",
    "        \"residents_pctchangewithref\": 2,\n",
    "    }\n",
    "    return df.round(col_dps)\n",
    "\n",
    "\n",
    "def round_relocations(df) -> DataFrame:\n",
    "    col_dps = {\n",
    "        \"relocations\": -1,\n",
    "        \"relocations_diffwithref\": -1,\n",
    "        \"abnormality\": 3,\n",
    "        \"relocations_pctchangewithref\": 2,\n",
    "    }\n",
    "    return df.round(col_dps)\n",
    "\n",
    "\n",
    "def round_movements(df) -> DataFrame:\n",
    "    col_dps = {\n",
    "        \"travellers\": -2,\n",
    "        \"abnormality\": 3,\n",
    "        \"travellers_diffwithref\": -1,\n",
    "        \"travellers_pctchangewithref\": 2,\n",
    "    }\n",
    "    return df.round(col_dps)\n",
    "\n",
    "\n",
    "def round_presence(df) -> DataFrame:\n",
    "    col_dps = {\n",
    "        \"presence\": -2,\n",
    "        \"presence_perKm2\": -1,\n",
    "        \"travellers_in\": -1,\n",
    "        \"travellers_out\": -1,\n",
    "        \"abnormality\": 3,\n",
    "        \"presence_diffwithref\": -1,\n",
    "        \"presence_pxtchangewithref\": 2,\n",
    "    }\n",
    "    return df.round(col_dps)\n",
    "\n",
    "\n",
    "if IS_FIRST_MONTH:\n",
    "    RESIDENTS_REDACTIONS = (\n",
    "        admin_3_drop_residents,\n",
    "        cdr_activity_redaction_residents,\n",
    "        residents_redaction,\n",
    "        round_residents,\n",
    "    )\n",
    "else:\n",
    "    RESIDENTS_REDACTIONS = (\n",
    "        admin_3_drop_residents,\n",
    "        cdr_pop_redaction_residents,\n",
    "        residents_redaction,\n",
    "        arrivals_departed_nan,\n",
    "        round_residents,\n",
    "    )\n",
    "\n",
    "RELOCATIONS_REDACTIONS = (\n",
    "    admin_3_drop_relocations,\n",
    "    cdr_pop_redaction_relocations,\n",
    "    relocations_redaction,\n",
    "    round_relocations,\n",
    ")\n",
    "\n",
    "PRESENCE_REDACTIONS = (\n",
    "    admin_3_drop_residents,\n",
    "    cdr_pop_redaction_residents,\n",
    "    presence_redaction,\n",
    "    round_presence,\n",
    ")\n",
    "\n",
    "MOVEMENTS_REDACTIONS = (\n",
    "    admin_3_drop_relocations,\n",
    "    cdr_pop_redaction_relocations,\n",
    "    travellers_redaction,\n",
    "    round_movements,\n",
    ")\n",
    "\n",
    "\n",
    "def redactor_factory(redaction_rules) -> callable:\n",
    "    def inner(df: DataFrame):\n",
    "        for rule in redaction_rules:\n",
    "            df = rule(df)\n",
    "        return df\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6169bc-fd1b-4b00-8769-450bf5f56359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE TO FUTURE NOTEBOOK SPELUNKERS: trid and srid are the victims of autogenerated code. They are not set in the db\n",
    "# until after data is uploaded, but you need them to upload data. This isn't an issue unless you've recently nuked the db.\n",
    "# If you _have_ nuked the db, this is the default starting values that seemed to work in the past - but if this nb is part\n",
    "# of a dag, you might need to go digging in `flowkit-ui-backend-db` (hosted on gcloud/sql at time of writing) to find out\n",
    "# what these actually map to if you're having issues. Love and kisses, John c. 2023\n",
    "\n",
    "\n",
    "def trid_lookup(trid_label):\n",
    "    trid_dict = {\"years\": 1, \"months\": 2, \"weeks\": 3, \"days\": 4}\n",
    "    return trid_dict[trid_label]\n",
    "\n",
    "\n",
    "def srid_lookup(srid_label):\n",
    "    srid_dict = {\"Commune\": 2, \"Communal section\": 3, \"Department\": 1}\n",
    "    return srid_dict[srid_label]\n",
    "\n",
    "\n",
    "def category_lookup(cat_label):\n",
    "    cat_dict = {\n",
    "        \"relocations\": \"flow\",\n",
    "        \"residents\": \"single_location\",\n",
    "        \"presence\": \"single_location\",\n",
    "        \"movements\": \"flow\",\n",
    "    }\n",
    "    return cat_dict[cat_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d5d40-4df9-4b49-b8c1-2647d1621744",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indicator_path, indicator_columns in INDICATORS.items():\n",
    "    indicator_path = Path(indicator_path)\n",
    "    print(indicator_path, indicator_columns)\n",
    "\n",
    "    if \"residents\" in indicator_path.name:\n",
    "        csv_ds = ResidentsDataset(indicator_path, indicators=indicator_columns)\n",
    "        local_redactor = redactor_factory(RESIDENTS_REDACTIONS)\n",
    "    elif \"relocations\" in indicator_path.name:\n",
    "        csv_ds = RelocationsDataset(indicator_path, indicators=indicator_columns)\n",
    "        local_redactor = redactor_factory(RELOCATIONS_REDACTIONS)\n",
    "    elif \"movements\" in indicator_path.name:\n",
    "        csv_ds = MovementsDataset(indicator_path, indicators=indicator_columns)\n",
    "        local_redactor = redactor_factory(MOVEMENTS_REDACTIONS)\n",
    "    elif \"presence\" in indicator_path.name:\n",
    "        csv_ds = PresenceDataset(indicator_path, indicators=indicator_columns)\n",
    "        local_redactor = redactor_factory(PRESENCE_REDACTIONS)\n",
    "    else:\n",
    "        raise InvalidIndicatorError(\n",
    "            f\"Invalid indicator {indicator_path.name}; must include one of 'residents', 'relocations', 'movements' or 'presence'.\"\n",
    "        )\n",
    "\n",
    "    validate_indicator(csv_ds, CONFIG_PATH)\n",
    "    print(csv_ds)\n",
    "\n",
    "    json_datasets = csv_to_dataset(\n",
    "        csv_ds,\n",
    "        srid_lookup=srid_lookup,\n",
    "        trid_lookup=trid_lookup,\n",
    "        category_type_lookup=category_lookup,\n",
    "        redactor=local_redactor,\n",
    "        revision=DATA_VERSION,\n",
    "        indicators=indicator_columns,\n",
    "    )\n",
    "\n",
    "    JSON_FOLDER.mkdir(exists_ok=True)\n",
    "\n",
    "    for ds in json_datasets:\n",
    "        (JSON_FOLDER / ds.filename).write_text(json.dumps(asdict(ds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
