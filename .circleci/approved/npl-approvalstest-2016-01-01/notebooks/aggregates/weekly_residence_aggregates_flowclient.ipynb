{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8b66f2-bd57-4029-bb52-149e547cc3af",
   "metadata": {},
   "source": [
    "James Harrison, 2022-06-01\n",
    "\n",
    "This notebook is used to produce the following aggregates:\n",
    "- Resident counts per 7-day rolling window\n",
    "- Home relocations between consecutive 7-day rolling windows (i.e. offset by 1 day, unless some 7-day windows are skipped due to missing data)\n",
    "- Home relocations between disjoint 7-day rolling windows (i.e. offset by 7 days)\n",
    "\n",
    "for each day in the specified date range (by default, the most recently-ended full calendar month before today).\n",
    "\n",
    "These aggregates are intended to be produced on an ongoing basis in preparation for crisis response work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1b1fc-c512-4cda-8fe6-8122b289aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import flowclient as fc\n",
    "import flowmachine as fm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from apply_subscriber_set import ApplySubscriberSet\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from flowclient import flows, inflows, outflows, spatial_aggregate\n",
    "from flowmachine.core.union import Union\n",
    "from flowmachine.features.subscriber.per_subscriber_aggregate import (\n",
    "    PerSubscriberAggregate,\n",
    ")\n",
    "from flowmachine.features.utilities.unique_values_from_queries import (\n",
    "    UniqueValuesFromQueries,\n",
    ")\n",
    "from get_secret_or_env_var import environ\n",
    "from total_locatable_periods import TotalLocatablePeriods\n",
    "from utils import (\n",
    "    daily_home_location_specs,\n",
    "    find_dates_to_exclude,\n",
    "    get_date_in_month,\n",
    "    rolling_window_over_date_range,\n",
    "    run_query_and_write_result,\n",
    "    run_query_and_write_result_async,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14443a00-5399-495a-94e5-c2942b10c93c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c5db11-1689-4cb2-b0ff-21dd8337238e",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc4a7b-58aa-4aeb-9a65-9e86278e5017",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_now = datetime.datetime.now()\n",
    "datetime_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d95bb8-dea3-44ba-b5b6-cb42eb18ea98",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "author = \"James Harrison <james.harrison@flowminder.org>\"\n",
    "\n",
    "start_date = get_date_in_month(\n",
    "    datetime_now, day_of_month=1, month_offset=-1\n",
    ")  # Start date of the data interval (inclusive)\n",
    "end_date = None  # End date of the data interval (exclusive) (defaults to one calendar month after start date)\n",
    "window_length = (\n",
    "    7  # Length in days of the rolling window used to compute average call days\n",
    ")\n",
    "min_call_days = (\n",
    "    2  # Minimal number of average days in a window a subscriber was sighted on\n",
    ")\n",
    "latest_truncation_threshold = (\n",
    "    \"18:00:00\"  # Threshold for excluding temporally-truncated data\n",
    ")\n",
    "\n",
    "aggregation_unit = \"lon-lat\"  # Spatial aggregation unit\n",
    "mapping_table = \"geography.cell_to_admin_via_clusters_1km_20221025\"\n",
    "geom_table = \"geography.clusters_1km_20221025\"\n",
    "geom_table_join_column = \"cluster_id\"\n",
    "event_types = [\"calls\"]  # Event types to use\n",
    "\n",
    "flowmachine_log_level = \"info\"  # Flowmachine log level\n",
    "shared_data_dir = \"./\"  # Writable output directory\n",
    "outputs_subdir = \"aggregates/crisis_response\"  # Subdirectory of shared data dir to which results of aggregate queries will be written\n",
    "output_format = \"csv\"  # 'csv' or 'netcdf'\n",
    "overwrite = False  # Set True to overwrite previously-saved aggregates for this month (with overwrite=False, conflicting aggregate files will be renamed)\n",
    "calculate_relocations = True  # Set False to skip running the home relocations aggregate\n",
    "require_latest_data = True  # If True, computation will not proceed if the last required day of data is later than the most recent available date\n",
    "include_subsetted = True  # Set False to skip calculating aggregates using an \"active subset\" of subscribers\n",
    "use_async_client = False  # Set True to use the asynchronous flowclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161bbd27-f2cc-494a-b2be-e18f1200d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start/end date parameters may be strings, so convert to datetime.date\n",
    "start_date = pd.Timestamp(start_date).date()\n",
    "if end_date is None:\n",
    "    end_date = start_date + relativedelta(months=1)\n",
    "end_date = pd.Timestamp(end_date).date()\n",
    "\n",
    "(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa3ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct outputs path (we don't actually create the dir until we're ready to start writing outputs later)\n",
    "outputs_path = (\n",
    "    Path(shared_data_dir)\n",
    "    / outputs_subdir\n",
    "    / f\"weekly_aggregates_{aggregation_unit}_{end_date:%Y-%m-%d}\"\n",
    ")\n",
    "\n",
    "outputs_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018b3f3-4fa6-4b4f-8500-8810980a03bc",
   "metadata": {},
   "source": [
    "## Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0ffbc-d504-4275-80a0-0cec45191c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_async_client:\n",
    "    fc_conn = await fc.connect_async(\n",
    "        url=environ[\"FLOWAPI_URL\"],\n",
    "        ssl_certificate=False,  # Workaround pending https://github.com/Flowminder/flowpyter-task/issues/35\n",
    "        token=environ[\"FLOWAPI_TOKEN\"],\n",
    "    )\n",
    "else:\n",
    "    fc_conn = fc.connect(\n",
    "        url=environ[\"FLOWAPI_URL\"],\n",
    "        ssl_certificate=False,  # Workaround pending https://github.com/Flowminder/flowpyter-task/issues/35\n",
    "        token=environ[\"FLOWAPI_TOKEN\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6ccd2-40c9-432a-b795-70b6f3f48072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even if we're not using a subscriber subset, flowmachine connection is required to get the earliest/latest event time per day\n",
    "fm.connect(\n",
    "    flowdb_connection_pool_overflow=20,\n",
    "    flowdb_connection_pool_size=5,\n",
    "    log_level=flowmachine_log_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18315e-f6e2-4a46-b161-cc69f83d6bce",
   "metadata": {},
   "source": [
    "## Check dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4bc884-bb8c-467f-b399-e80498eb4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_to_skip = find_dates_to_exclude(\n",
    "    flowdb_connection=fm.core.context.get_db(),\n",
    "    start_date=start_date - relativedelta(days=window_length),\n",
    "    end_date=end_date,\n",
    "    event_types=event_types,\n",
    "    latest_truncation_threshold=latest_truncation_threshold,\n",
    "    fail_on_missing_latest=require_latest_data,\n",
    ")\n",
    "dates_to_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a403ae8-cbab-4194-bf2f-1426c8d7a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rolling windows\n",
    "rolling_windows = rolling_window_over_date_range(\n",
    "    start_date=start_date - relativedelta(days=window_length),\n",
    "    end_date=end_date,\n",
    "    window_length=window_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b3461d-8ce4-4bcd-82c5-9393d42466f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for empty windows\n",
    "empty_windows = sorted(\n",
    "    [\n",
    "        d\n",
    "        for d in rolling_windows\n",
    "        if not set(\n",
    "            str(d.date())\n",
    "            for d in pd.date_range(\n",
    "                rolling_windows[d][0], rolling_windows[d][1], inclusive=\"left\"\n",
    "            )\n",
    "        ).difference(dates_to_skip)\n",
    "    ]\n",
    ")\n",
    "\n",
    "if empty_windows:\n",
    "    warnings.warn(\n",
    "        f\"Windows for dates {empty_windows} have no data. Aggregates will not be produced for these dates.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6bb495-c07b-4f08-8928-a4ae1faaf43b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Subscriber subset\n",
    "\n",
    "Subscriber subsets have to be defined and run using flowmachine directly, and then the query IDs can be used to subset FlowAPI queries.\n",
    "\n",
    "Subscriber subset is the set of subscribers who are active on `min_call_days` days in every non-empty `window_length`-day rolling window on average (median) over the specified date range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f467158-2b3d-4052-911b-c4889f01e02d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define subscriber subset queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49fe56d-2b76-44cb-8aa3-4c4ee6638d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_subsetted:\n",
    "    tables = [f\"events.{event_type}\" for event_type in event_types]\n",
    "    # Convert FlowAPI aggregation unit parameters to a flowmachine spatial unit\n",
    "    if \"admin\" in aggregation_unit:\n",
    "        spatial_unit = fm.core.spatial_unit.make_spatial_unit(\n",
    "            spatial_unit_type=\"admin\",\n",
    "            level=int(aggregation_unit[-1]),\n",
    "            mapping_table=mapping_table,\n",
    "            geom_table=geom_table,\n",
    "            geom_table_join_on=geom_table_join_column,\n",
    "        )\n",
    "    else:\n",
    "        spatial_unit = fm.core.spatial_unit.make_spatial_unit(\n",
    "            spatial_unit_type=aggregation_unit,\n",
    "            mapping_table=mapping_table,\n",
    "            geom_table=geom_table,\n",
    "            geom_table_join_on=geom_table_join_column,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a21bb0f-af75-4eeb-b329-5ba7d511c0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subset of subscribers with median call days per non-empty window >= `min_call_days`\n",
    "\n",
    "if include_subsetted:\n",
    "    # Count call days per subscriber per window over the month\n",
    "    # (excluding the first window_length windows because these belong to the previous month)\n",
    "    active_periods_queries = []\n",
    "    for window in sorted(\n",
    "        d\n",
    "        for d in rolling_windows.keys()\n",
    "        if datetime.date.fromisoformat(d) >= start_date\n",
    "    ):\n",
    "        try:\n",
    "            active_periods_queries.append(\n",
    "                TotalLocatablePeriods(\n",
    "                    start=rolling_windows[window][0],\n",
    "                    total_periods=window_length,\n",
    "                    period_length=1,\n",
    "                    period_unit=\"days\",\n",
    "                    spatial_unit=spatial_unit,\n",
    "                    table=tables,\n",
    "                    periods_to_exclude=dates_to_skip,\n",
    "                )\n",
    "            )\n",
    "        except ValueError:\n",
    "            # If all dates in this window are excluded, skip it\n",
    "            pass\n",
    "\n",
    "    # Need to fill counts with 0 for windows where a subscriber was inactive,\n",
    "    # so that the median can be calculated correctly. For this we need the set of\n",
    "    # all subscribers active in any of the windows.\n",
    "    all_active_subscribers_query = UniqueValuesFromQueries(\n",
    "        query_list=active_periods_queries,\n",
    "        column_names=\"subscriber\",\n",
    "    )\n",
    "    active_periods_for_all_subscribers_queries = []\n",
    "    for active_periods_query in active_periods_queries:\n",
    "        active_periods_for_all_subscribers_queries.append(\n",
    "            ApplySubscriberSet(\n",
    "                parent=active_periods_query,\n",
    "                subscriber_set=all_active_subscribers_query,\n",
    "                fill_values={\"value\": 0},\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Find subset of subscribers that were active at least min_call_days days per window (median)\n",
    "    subset_query = PerSubscriberAggregate(\n",
    "        subscriber_query=Union(*active_periods_for_all_subscribers_queries),\n",
    "        agg_column=\"value\",\n",
    "        agg_method=\"median\",\n",
    "    ).numeric_subset(high=np.inf, low=min_call_days, col=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b97fc0f-cb5a-4723-a76b-5d0763901c7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run subscriber subset query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf09877-5d96-47c3-95cc-386fb5f6bcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if include_subsetted:\n",
    "    subset_query.store(store_dependencies=True).result()\n",
    "    len(subset_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4f706-817a-4b06-aa45-2f19b6b8f030",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wrap in Table object so that flowmachine server can unpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb075eb5-ba01-4fc3-bba0-f4eb42adccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_subsetted:\n",
    "    subscriber_subset_table = subset_query.get_table()\n",
    "    subscriber_subset_query_id = subscriber_subset_table.query_id\n",
    "    subscriber_subset_query_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c8a8c-9d17-4e25-a1fe-56e42de0d8ad",
   "metadata": {},
   "source": [
    "Subset query id can now be passed on to API queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bafa820-0462-4e0c-ab76-a7807826d0ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FlowAPI side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a0317-ca5c-4c77-98c3-33342db440b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5d900-4f6b-444a-8c71-671dba16ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_queries = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb658e89-7ecc-4b77-87c2-6a131d776a31",
   "metadata": {},
   "source": [
    "### Home location sub-queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f3d126-99fd-4129-8f0a-ce423da324dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_subsetted:\n",
    "    home_location_specs_subset = daily_home_location_specs(\n",
    "        rolling_windows=rolling_windows,\n",
    "        aggregation_unit=aggregation_unit,\n",
    "        mapping_table=mapping_table,\n",
    "        geom_table=geom_table,\n",
    "        geom_table_join_column=geom_table_join_column,\n",
    "        subscriber_subset=subscriber_subset_query_id,\n",
    "        event_types=event_types,\n",
    "        dates_to_exclude=dates_to_skip,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2349fb-02c8-451f-be14-2b906dfcce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_location_specs_nosubset = daily_home_location_specs(\n",
    "    rolling_windows=rolling_windows,\n",
    "    aggregation_unit=aggregation_unit,\n",
    "    mapping_table=mapping_table,\n",
    "    geom_table=geom_table,\n",
    "    geom_table_join_column=geom_table_join_column,\n",
    "    subscriber_subset=None,\n",
    "    event_types=event_types,\n",
    "    dates_to_exclude=dates_to_skip,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a5ac7-778b-4932-ac92-6158459720a3",
   "metadata": {},
   "source": [
    "### Resident counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f852c67-f082-4fe8-8112-56495392ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_subsetted:\n",
    "    for d in home_location_specs_subset:\n",
    "        # Don't produce resident counts for windows before start_date\n",
    "        if datetime.date.fromisoformat(d) >= start_date:\n",
    "            api_queries[f\"resident-counts_subset_{d}\"] = spatial_aggregate(\n",
    "                connection=fc_conn,\n",
    "                locations=home_location_specs_subset[d],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80c804-04f6-4f52-8839-a72c84e78adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in home_location_specs_nosubset:\n",
    "    # Don't produce resident counts for windows before start_date\n",
    "    if datetime.date.fromisoformat(d) >= start_date:\n",
    "        api_queries[f\"resident-counts_nosubset_{d}\"] = spatial_aggregate(\n",
    "            connection=fc_conn,\n",
    "            locations=home_location_specs_nosubset[d],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb53ef7-f017-4684-8823-52fe1803c6b4",
   "metadata": {},
   "source": [
    "### Home relocations matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c6042-c8e2-4bbc-bb41-9d8f42971b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_relocations:\n",
    "    non_empty_windows = sorted(home_location_specs_nosubset.keys())\n",
    "    for d_from, d_to in zip(non_empty_windows[:-1], non_empty_windows[1:]):\n",
    "        # Home relocations between consecutive windows (don't produce relocations for 'to' windows before start_date)\n",
    "        if datetime.date.fromisoformat(d_to) >= start_date:\n",
    "            if include_subsetted:\n",
    "                api_queries[\n",
    "                    f\"home-relocations_consecutive_subset_from{d_from}_to{d_to}\"\n",
    "                ] = flows(\n",
    "                    connection=fc_conn,\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to],\n",
    "                    join_type=\"full outer\",\n",
    "                )\n",
    "                api_queries[\n",
    "                    f\"home-relocations-in_consecutive_subset_from{d_from}_to{d_to}\"\n",
    "                ] = inflows(\n",
    "                    connection=fc_conn,\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to],\n",
    "                    join_type=\"inner\",\n",
    "                )\n",
    "                api_queries[\n",
    "                    f\"home-relocations-out_consecutive_subset_from{d_from}_to{d_to}\"\n",
    "                ] = outflows(\n",
    "                    connection=fc_conn,\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to],\n",
    "                    join_type=\"inner\",\n",
    "                )\n",
    "            api_queries[\n",
    "                f\"home-relocations_consecutive_nosubset_from{d_from}_to{d_to}\"\n",
    "            ] = flows(\n",
    "                connection=fc_conn,\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to],\n",
    "                join_type=\"full outer\",\n",
    "            )\n",
    "            api_queries[\n",
    "                f\"home-relocations-in_consecutive_nosubset_from{d_from}_to{d_to}\"\n",
    "            ] = inflows(\n",
    "                connection=fc_conn,\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to],\n",
    "                join_type=\"inner\",\n",
    "            )\n",
    "            api_queries[\n",
    "                f\"home-relocations-out_consecutive_nosubset_from{d_from}_to{d_to}\"\n",
    "            ] = outflows(\n",
    "                connection=fc_conn,\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to],\n",
    "                join_type=\"inner\",\n",
    "            )\n",
    "        # Home relocations between disjoint windows\n",
    "        d_to_disjoint = str(\n",
    "            (pd.Timestamp(d_from) + pd.Timedelta(days=window_length)).date()\n",
    "        )\n",
    "        if d_to_disjoint in non_empty_windows:\n",
    "            if include_subsetted:\n",
    "                api_queries[\n",
    "                    f\"home-relocations_disjoint_subset_from{d_from}_to{d_to_disjoint}\"\n",
    "                ] = flows(\n",
    "                    connection=fc_conn,\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to_disjoint],\n",
    "                    join_type=\"full outer\",\n",
    "                )\n",
    "                api_queries[\n",
    "                    f\"home-relocations-in_disjoint_subset_from{d_from}_to{d_to_disjoint}\"\n",
    "                ] = inflows(\n",
    "                    connection=fc_conn,\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to_disjoint],\n",
    "                    join_type=\"inner\",\n",
    "                )\n",
    "                api_queries[\n",
    "                    f\"home-relocations-out_disjoint_subset_from{d_from}_to{d_to_disjoint}\"\n",
    "                ] = outflows(\n",
    "                    connection=fc_conn,\n",
    "                    from_location=home_location_specs_subset[d_from],\n",
    "                    to_location=home_location_specs_subset[d_to_disjoint],\n",
    "                    join_type=\"inner\",\n",
    "                )\n",
    "            api_queries[\n",
    "                f\"home-relocations_disjoint_nosubset_from{d_from}_to{d_to_disjoint}\"\n",
    "            ] = flows(\n",
    "                connection=fc_conn,\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to_disjoint],\n",
    "                join_type=\"full outer\",\n",
    "            )\n",
    "            api_queries[\n",
    "                f\"home-relocations-in_disjoint_nosubset_from{d_from}_to{d_to_disjoint}\"\n",
    "            ] = inflows(\n",
    "                connection=fc_conn,\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to_disjoint],\n",
    "                join_type=\"inner\",\n",
    "            )\n",
    "            api_queries[\n",
    "                f\"home-relocations-out_disjoint_nosubset_from{d_from}_to{d_to_disjoint}\"\n",
    "            ] = outflows(\n",
    "                connection=fc_conn,\n",
    "                from_location=home_location_specs_nosubset[d_from],\n",
    "                to_location=home_location_specs_nosubset[d_to_disjoint],\n",
    "                join_type=\"inner\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88148602-ac8b-455e-a2f5-98fb2b3d5aaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run queries and write results to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_attrs = {\n",
    "    \"author\": author,\n",
    "    \"redacted\": True,\n",
    "    \"excluded_dates\": sorted(dates_to_skip),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ead5f-5e18-4ad1-a3c6-029cda9eaa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7febb30e-0599-42f0-bdbf-7f235ee89354",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_async_client:\n",
    "    awaitables = [\n",
    "        run_query_and_write_result_async(\n",
    "            query,\n",
    "            filepath=outputs_path / label,\n",
    "            overwrite=overwrite,\n",
    "            file_format=output_format,\n",
    "            additional_attrs=additional_attrs,\n",
    "        )\n",
    "        for label, query in api_queries.items()\n",
    "    ]\n",
    "else:\n",
    "    # If using the sync client, we want to set all queries running before waiting on any results\n",
    "    for label, query in api_queries.items():\n",
    "        print(f\"Setting '{label}' query running...\")\n",
    "        query.run()\n",
    "    print(\"All queries are running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc626719-7b6b-428b-b752-514cd20e9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_async_client:\n",
    "    import asyncio\n",
    "\n",
    "    await asyncio.gather(*awaitables)\n",
    "else:\n",
    "    for label, query in api_queries.items():\n",
    "        print(f\"Getting result of '{label}' query...\")\n",
    "        run_query_and_write_result(\n",
    "            query,\n",
    "            filepath=outputs_path / label,\n",
    "            overwrite=overwrite,\n",
    "            file_format=output_format,\n",
    "            additional_attrs=additional_attrs,\n",
    "        )\n",
    "print(\"All queries completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc89c6a-8250-45da-aff5-644294a31d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
